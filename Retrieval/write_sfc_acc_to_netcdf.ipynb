{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/franzihe/Documents/Python/Thesis/')#MEPS/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import createFolder as cF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = 'Haukeliseter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dir = '../../../Data/Retrieval/%s/' %station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ['10', '11', '12', '01', '02', '03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_filename = 'minute_surface_acc_Haukeli.dat.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_netCDF_variable(f, var_name, var, dim):\n",
    "    v_0m = f.createVariable(varname=var_name, datatype=var.dtype, dimensions=dim, zlib=True)\n",
    "    v_0m[:] = var[:]\n",
    "    return(v_0m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in m:\n",
    "    if month == '10':\n",
    "        t = np.arange(16,32)\n",
    "    if month == '11':\n",
    "        t = np.arange(1,31)\n",
    "    if month == '12' or month == '01' or month == '03':\n",
    "        t = np.arange(1,32)\n",
    "    if month == '02':\n",
    "        t = np.arange(1,29)\n",
    "    if month == '10' or month == '11' or month == '12':\n",
    "        year = '2016'\n",
    "    if month == '01' or month == '02' or month == '03':\n",
    "        year = '2017'\n",
    "        \n",
    "    for day in t:\n",
    "        \n",
    "        if day < 10:\n",
    "            day = '0%s' %day\n",
    "        else:\n",
    "            day = '%s' %day\n",
    "        \n",
    "        Date = int(year+month+day)\n",
    "        \n",
    "        \n",
    "        Haukeli_p = pd.read_fwf(txt_dir + 'pulsed_'+txt_filename, header = 1)\n",
    "        idx_p = np.where(Haukeli_p['Unnamed: 0'] == Date)\n",
    "        \n",
    "        if np.array(idx_p).shape[1] == 1:\n",
    "                precip_24 = (Haukeli_p['Unnamed: 1'][idx_p[0][0]])\n",
    "                precip_24 = np.array([precip_24])\n",
    "                \n",
    "                #read in the surface snowfall rate for each minute\n",
    "                column0 = Haukeli_p['Unnamed: 0'][idx_p[0][0]+1:int(idx_p[0][0]+1440/6+1)]\n",
    "                column1 = Haukeli_p['Unnamed: 1'][idx_p[0][0]+1:int(idx_p[0][0]+1440/6+1)]\n",
    "                column2 = Haukeli_p['Unnamed: 2'][idx_p[0][0]+1:int(idx_p[0][0]+1440/6+1)]\n",
    "                column3 = Haukeli_p['Unnamed: 3'][idx_p[0][0]+1:int(idx_p[0][0]+1440/6+1)]\n",
    "                column4 = Haukeli_p['Unnamed: 4'][idx_p[0][0]+1:int(idx_p[0][0]+1440/6+1)]\n",
    "                column5 = Haukeli_p['Unnamed: 5'][idx_p[0][0]+1:int(idx_p[0][0]+1440/6+1)]\n",
    "        \n",
    "                ret_pulsed = pd.concat([column0, column1, column2, column3, column4, column5], axis =1)\n",
    "                ret_pulsed = np.array(ret_pulsed)\n",
    "                ret_pulsed = ret_pulsed.flatten()/ret_pulsed.flatten().shape[0]\n",
    "                \n",
    "        Haukeli_u = pd.read_fwf(txt_dir + 'upslope_'+txt_filename, header = 1)\n",
    "        idx_u = np.where(Haukeli_u['Unnamed: 0'] == Date)\n",
    "        \n",
    "        if np.array(idx_u).shape[1] == 1:\n",
    "                precip_24 = (Haukeli_u['Unnamed: 1'][idx_u[0][0]])\n",
    "                precip_24 = np.array([precip_24])\n",
    "                \n",
    "                #read in the surface snowfall rate for each minute\n",
    "                column0_u = Haukeli_u['Unnamed: 0'][idx_u[0][0]+1:int(idx_u[0][0]+1440/6+1)]\n",
    "                column1_u = Haukeli_u['Unnamed: 1'][idx_u[0][0]+1:int(idx_u[0][0]+1440/6+1)]\n",
    "                column2_u = Haukeli_u['Unnamed: 2'][idx_u[0][0]+1:int(idx_u[0][0]+1440/6+1)]\n",
    "                column3_u = Haukeli_u['Unnamed: 3'][idx_u[0][0]+1:int(idx_u[0][0]+1440/6+1)]\n",
    "                column4_u = Haukeli_u['Unnamed: 4'][idx_u[0][0]+1:int(idx_u[0][0]+1440/6+1)]\n",
    "                column5_u = Haukeli_u['Unnamed: 5'][idx_u[0][0]+1:int(idx_u[0][0]+1440/6+1)]\n",
    "        \n",
    "                ret_upslope = pd.concat([column0_u, column1_u, column2_u, column3_u, column4_u, column5_u], axis =1)\n",
    "                ret_upslope = np.array(ret_upslope)\n",
    "                ret_upslope = ret_upslope.flatten()/ret_upslope.flatten().shape[0]\n",
    "         \n",
    "        ### write netCDF file\n",
    "        cF.createFolder(txt_dir+txt_filename.split()[0][0:-16]+'/')\n",
    "        fw = netCDF4.Dataset(txt_dir+txt_filename.split()[0][0:-16]+'/%s.nc' %Date, 'w')\n",
    "        ### create dimensions\n",
    "        fw.createDimension('time', ret_pulsed.shape[0])\n",
    "        \n",
    "        ret_pulsed_w = get_netCDF_variable(fw, 'pulsed_sfc_acc', ret_pulsed, ('time',))\n",
    "        ret_upslope_w = get_netCDF_variable(fw, 'upslope_sfc_acc', ret_upslope, ('time',))\n",
    "        \n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
