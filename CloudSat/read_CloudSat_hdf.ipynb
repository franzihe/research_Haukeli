{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcefolder = '../../../../Downloads'\n",
    "\n",
    "f = ['PRECIP-COLUMN', 'SNOW-PROFILE']\n",
    "#year_month = 201611\n",
    "#t = ['2016317111800_56087',\n",
    " #   '2016318102222_56101',\n",
    "  #  '2016321105315_56145',\n",
    "   # '2016322095737_56159',\n",
    "    #'2016323104052_56174',\n",
    "    #'2016334102212_56334']\n",
    "#year_month =  201612\n",
    "#t = ['2016356112357_56655', \n",
    " #     '2016357102821_56669',\n",
    "  #    '2016358111138_56684',\n",
    "   #   '2016359101602_56698',\n",
    "    #  '2016360105918_56713',\n",
    "     # '2016361100342_56727']\n",
    "year_month = 201701\n",
    "t = ['2017003105316_56844',\n",
    "    '2017006112413_56888',\n",
    "    '2017009101617_56931',\n",
    "    '2017010105933_56946',\n",
    "    '2017011100357_56960',\n",
    "    '2017012104713_56975',\n",
    "    '2017013095137_56989',\n",
    "     '2017029095148_57222',\n",
    "    '2017029113041_57223']\n",
    "#year_month = 201702\n",
    "#t = ['2017033110600_57281',\n",
    " #   '2017034101023_57295',\n",
    "  #  '2017035105339_57310']\n",
    "\n",
    "targetfolder = '../../Data/CloudSat/2C_Precip/%s/' %year_month\n",
    "savefig = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file in f:\n",
    "    if file == 'PRECIP-COLUMN':\n",
    "        processing = 'P2'\n",
    "    elif file == 'SNOW-PROFILE':\n",
    "        processing = 'P'\n",
    "    \n",
    "    for day in t:\n",
    "        with zipfile.ZipFile(\"%s/%s_CS_2C-%s_GRANULE_%s_R04_E06.hdf.zip\" %(sourcefolder,day,file,processing),\"r\") as zip_ref:\n",
    "            zip_ref.extractall(targetfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.science-emergence.com/Articles/How-to-read-a-MODIS-HDF-file-using-python-/\n",
    "\n",
    "https://www.science-emergence.com/Articles/How-to-read-CloudSat-2B-GEOPROF-GRANULE-HDF4-file-using-python-and-pyhdf-/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/uio/kant/geo-metos-u7/franzihe/Documents/Thesis/Python')\n",
    "import createFolder as cF\n",
    "### Import python libraries\n",
    "from pyhdf.SD import SD, SDC\n",
    "from pyhdf.HDF import *\n",
    "from pyhdf.VS import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.basemap import shiftgrid\n",
    "\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_lat      = 59.81\n",
    "stn_lon      = 7.21\n",
    "\n",
    "lower_lat = stn_lat -2.\n",
    "upper_lat = stn_lat +2.\n",
    "\n",
    "left_lon = stn_lon -2.\n",
    "right_lon = stn_lon +2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.trondkristiansen.com/?page_id=846\n",
    "\n",
    "Since the ETOPO1 file is quite large (445MB) I added a function to the script that cuts out only the area of interest from the ETOPO1 file. This saves space and time (see function: findSubsetIndices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSubsetIndices(min_lat,max_lat,min_lon,max_lon,lats,lons):\n",
    "    \n",
    "    \"\"\"Array to store the results returned from the function\"\"\"\n",
    "    res=np.zeros((4),dtype=np.float64)\n",
    "    minLon=min_lon; maxLon=max_lon\n",
    "    \n",
    "    distances1 = []; distances2 = []\n",
    "    indices=[]; index=1\n",
    "    \n",
    "    for point in lats:\n",
    "        s1 = max_lat-point # (vector subtract)\n",
    "        s2 = min_lat-point # (vector subtract)\n",
    "        distances1.append((np.dot(s1, s1), point, index))\n",
    "        distances2.append((np.dot(s2, s2), point, index-1))\n",
    "        index=index+1\n",
    "        \n",
    "    distances1.sort()\n",
    "    distances2.sort()\n",
    "    indices.append(distances1[0])\n",
    "    indices.append(distances2[0])\n",
    "    \n",
    "    distances1 = []; distances2 = []; index=1\n",
    "   \n",
    "    for point in lons:\n",
    "        s1 = maxLon-point # (vector subtract)\n",
    "        s2 = minLon-point # (vector subtract)\n",
    "        distances1.append((np.dot(s1, s1), point, index))\n",
    "        distances2.append((np.dot(s2, s2), point, index-1))\n",
    "        index=index+1\n",
    "        \n",
    "    distances1.sort()\n",
    "    distances2.sort()\n",
    "    indices.append(distances1[0])\n",
    "    indices.append(distances2[0])\n",
    "    \n",
    "    \"\"\" Save final product: max_lat_indices,min_lat_indices,max_lon_indices,min_lon_indices\"\"\"\n",
    "    minJ=indices[1][2] # min_lat_indices\n",
    "    maxJ=indices[0][2]\n",
    "    minI=indices[3][2]\n",
    "    maxI=indices[2][2] # max_lon_indices\n",
    "    \n",
    "    res[0]=minI; res[1]=maxI; res[2]=minJ; res[3]=maxJ;\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in f:\n",
    "    if file == 'PRECIP-COLUMN':\n",
    "        processing = 'P2'\n",
    "    elif file == 'SNOW-PROFILE':\n",
    "        processing = 'P'\n",
    "for day in t:\n",
    "    file_path = targetfolder\n",
    "    file_name = '/%s_CS_2C-%s_GRANULE_%s_R04_E06.hdf' %(day,file,processing)\n",
    "\n",
    "### Read latitudes and longitudes, profile time\n",
    "    f = HDF(file_path+file_name, SDC.READ) \n",
    "    vs = f.vstart()\n",
    "\n",
    "    data_info_list = vs.vdatainfo()\n",
    "\n",
    "#pprint.pprint( data_info_list )\n",
    "\n",
    "    vdata_lat = vs.attach('Latitude')\n",
    "    vdata_long = vs.attach('Longitude')\n",
    "\n",
    "    vdata_profile_time = vs.attach('Profile_time')\n",
    "    vdata_snowfall_rate_sfc = vs.attach('snowfall_rate_sfc')\n",
    "\n",
    "\n",
    "\n",
    "    lat = vdata_lat[:]\n",
    "    long = vdata_long[:]\n",
    "\n",
    "    profile_time = vdata_profile_time[:]\n",
    "    snowfall_rate_sfc = vdata_snowfall_rate_sfc[:]\n",
    "\n",
    "\n",
    "#print('Nb pixels: ', len(lat))\n",
    "#print('Lat min, Lat max: ',min(lat),max(lat))\n",
    "\n",
    "#for i in range(15): # sample\n",
    " #   print(lat[i])\n",
    "\n",
    "# to get vdata latitude info\n",
    "#print( vdata_lat.attrinfo() )        \n",
    "        \n",
    "    vdata_lat.detach() # \"close\" the vdata\n",
    "    vdata_long.detach() # \"close\" the vdata\n",
    "    vdata_profile_time.detach()\n",
    "    vdata_snowfall_rate_sfc.detach()\n",
    "    vs.end() # terminate the vdata interface\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a basemap to show the data\n",
    "    m = Basemap(projection='cyl',llcrnrlat=lower_lat-2,urcrnrlat=upper_lat+2, \n",
    "            llcrnrlon=left_lon-2,urcrnrlon=right_lon+2,resolution='c')\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90.,90.,30.),labels=[False,True,True,False])\n",
    "    m.drawmeridians(np.arange(-180.,180.,30.),labels=[True,False,False,True])\n",
    "    \n",
    "    x,y = m(long,lat)\n",
    "\n",
    "\n",
    "    m.scatter(x,y,3,marker='o',color='b')\n",
    "    m.scatter(stn_lon,stn_lat,5, marker='x')\n",
    "    plt.title(\"Cloudsat Trajectory %s\" %day)\n",
    "\n",
    "    if savefig == 1:\n",
    "        fig_dir = '../../Figures/cloudsat_trajectory/%s/' %(year_month)\n",
    "        cF.createFolder(fig_dir)\n",
    "        plt.savefig(fig_dir+\"%s_2deg.png\"  %day, bbox_inches='tight', dpi=200)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#    res = findSubsetIndices(lower_lat,upper_lat,left_lon,right_lon,np.array(lat),np.array(long))\n",
    "\n",
    " #   lons, lats = np.meshgrid(long,lat)\n",
    "\n",
    "  #  data, la = np.meshgrid(snowfall_rate_sfc, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
